---
title: "Assignment 2 Task 2"
author: "Amelia Ritger"
date: "3/9/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      messages=FALSE,
                      warnings=FALSE)
```

Create a single knitted HTML that introduces the document, describes the goals of your analyses, shows your beautifully organized code + nice analyses + finalized data visualizations, and briefly describes some of your findings. Some questions might be: 

What (non-stop) words are most common in the document?
How many words are associated with each sentiment? 
How does sentiment analysis compare for the different lexicons? 
How many times do words of interest to you appear in the text? 
How do sentiment/top words compare for speeches/documents/etc. from two or more different groups, candidates, etc.?

You should include at least 2 finalized visualizations (e.g. word cloud, graphs/visualizations of word counts & sentiment analysis, etc.) for this task, with summaries of your major observations for each. 

## Load packages and data
```{r}
library(tidyverse)
library(here)
library(pdftools)
library(tidytext)
library(textdata)
library(ggwordcloud)

path <- here("Silent_Spring-Rachel_Carson-1962.pdf")
spring_text <- pdftools::pdf_text(path)
```

## Do some wrangling
```{r}
spring <- data.frame(spring_text) %>%
  mutate(text_full = str_split(spring_text, pattern = "\r\n")) %>%  #split up existing strings in rows, at each line break >> each line shows up as a difference piece of a string
  unnest(text_full) %>% 
  mutate(text_full = str_trim(text_full)) %>% #get rid of empty space endpoints
  unnest_tokens(word,text_full) #give every word its own row
```

How many of each word are in the book?
```{r}
spring_wc <- spring %>% 
  count(word) %>% 
  arrange(-n)
```

## Remove stop words
```{r}
spring_stop <- spring %>% 
  anti_join(stop_words) %>% #remove stopwords from ipcc_token
  dplyr::select(-spring_text)
```

## Remove all numeric pieces:
```{r}
spring_no_numeric <- spring_stop %>% 
  dplyr::filter(is.na(as.numeric(word))) #for every entry in "word" column, convert it to a number - if it's not a number, return NA
```

## Start doing some visualization

Word cloud
```{r}
spring_top100 <- spring_no_numeric %>%
  mutate(word = str_replace_all(word,c("[^[:alnum:]]$" = "",  "s$" = "", "(\\(\\d*)" = "\\1\\)" ))) %>% #combine plural and singular words
  count(word) %>% 
  arrange(-n) %>% 
  head(100) 

ggplot(data=spring_top100, aes(label=word, size=n)) +
  geom_text_wordcloud(aes(color=n), shape="diamond") +
  scale_size_area(max_size=12) +
  scale_color_gradientn(colors = c("darkgreen", "blue", "red")) +
  theme_minimal()
```

Sentiment analysis